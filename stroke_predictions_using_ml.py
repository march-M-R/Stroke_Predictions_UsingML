# -*- coding: utf-8 -*-
"""Copy of stroke predictions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JBOC1eA2RN2pKlSxZ107C9ma5joLHpw2
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

!pip install anvil-uplink

import anvil.server

anvil.server.connect("server_L66T5L23NNEVG6FBJU3T3N3N-WFMCHLHPYAFUHDZD")

!pip install imblearn

df=pd.read_csv("/content/healthcare-dataset-stroke-data.csv")

df.head()

df.columns

df.describe()

df.shape

df.isnull().sum()

bmi_mean = df['bmi'].mean()
df['bmi'].fillna(value=bmi_mean, inplace=True)
bmi_mean

df.isnull().sum().sum()

df.drop('id', axis=1, inplace=True)

df.shape

sns.countplot(x='gender', data=df, hue='stroke');

df['gender'].value_counts()

df.drop(df.loc[df['gender']=='Other'].index, inplace=True)
df['gender'].value_counts()

sns.countplot(x='gender', data=df, hue='stroke');

plt.figure(figsize=(12,5))
sns.lineplot(data=df, x="age", y="bmi", hue='gender', ci=None);

plt.figure(figsize=(12,5))
sns.lineplot(data=df, x="age", y="avg_glucose_level", hue='stroke', ci=None);

plt.figure(figsize=(12,10))

sns.distplot(df[df['stroke'] == 0]["bmi"], color='blue')
sns.distplot(df[df['stroke'] == 1]["bmi"], color='red')

plt.title('No Stroke vs Stroke by BMI', fontsize=15)
plt.xlim([10,100])
plt.show()

fig = plt.figure(figsize=(7,7))
sns.distplot(df.avg_glucose_level, color="blue", label="avg_glucose_level", kde= True)
plt.legend();

plt.figure(figsize=(12,5))
sns.histplot(x='bmi', hue='ever_married', data=df, bins=50)

sns.pairplot(df, size = 1.0)

correlation = df.corr()
fig, axes = plt.subplots(figsize=(7, 7))
sns.heatmap(correlation, vmax=.8, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10});

df = pd.get_dummies(df,columns=['gender','work_type'])

df = pd.get_dummies(df,columns=['ever_married','Residence_type','smoking_status'])

df

df.columns

X = df.drop(["stroke"], axis = 1).values
y = df.iloc[:, 5].values

X

X.shape

y

y.shape

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

l_e = LabelEncoder()
X[:, 0] = l_e.fit_transform(X[:, 0]) # gender column
X[:, 4] = l_e.fit_transform(X[:, 4]) # ever_married column
X[:, 6] = l_e.fit_transform(X[:, 6])
X[:, 6] = l_e.fit_transform(X[:, 6]) # Residence_type column

c_t = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [5,9])], remainder= 'passthrough')
X = np.array(c_t.fit_transform(X))

X

X_train1 = pd.DataFrame(X)

column_names = X_train1.columns
column_names

X.shape, y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, y_train.shape, X_test.shape, y_test.shape

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

print (sum(y_train == 1))
print (sum(y_train == 0))

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train.ravel())

print (X_train.shape)
print (y_train.shape)
print (sum(y_train == 1))
print (sum(y_train == 0))

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier

from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve,  auc, precision_recall_curve, average_precision_score
from sklearn.model_selection import cross_val_score

"""# 1- LogisticRegression"""

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
score = cross_val_score(model, X_train, y_train, cv = 6)
precision = precision_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
rm = accuracy_score(y_test,y_pred)

print ('train score of LogisticRegression is', score.mean(),'%')
print ('--')
print ('Precision score is ', precision)
print ('--')
print ('ROC Score is', roc)
print ('--')
print ('Recall Score is ', recall)
print('accuracy score is ', rm)

y_pred_prob = model.predict_proba(X_test)[:,1]

# instantiating the roc_cruve
fpr,tpr,threshols=roc_curve(y_test,y_pred_prob)

# plotting the curve
plt.figure(figsize = (8, 8))
plt.plot([0,1],[0,1],"k--",'r+')
figsize=(16,12)
plt.plot(fpr,tpr,color = '#b01717', label = 'AUC = %0.3f' % roc)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(" Logistic Regression ROC Curve")
plt.legend()
plt.show()

y_test.shape

plt.figure(figsize = (8, 5))
sns.heatmap(cm, cmap = 'Oranges', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},
            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])
plt.yticks(rotation = 0)
plt.show()

"""# 2 - Support Vector Machine"""

model = SVC(probability=True)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
score = cross_val_score(model, X_train, y_train, cv = 6)
precision = precision_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
rm = accuracy_score(y_test,y_pred)

print ('train score of SVC is', score.mean(),'%')
print ('--')
print ('Precision score is ', precision)
print ('--')
print ('ROC Score is', roc)
print ('--')
print ('Recall Score is ', recall)
print('accuracy score is ', rm)

y_pred_prob = model.predict_proba(X_test)[:,1]
# instantiating the roc_cruve
fpr,tpr,threshols=roc_curve(y_test,y_pred_prob)

# plotting the curve
plt.figure(figsize = (8, 8))
plt.plot([0,1],[0,1],"k--",'r+')
figsize=(16,12)
plt.plot(fpr,tpr,color = '#b01717', label = 'AUC = %0.3f' % roc)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(" SVC ROC Curve")
plt.legend()
plt.show()

plt.figure(figsize = (8, 5))
sns.heatmap(cm, cmap = 'Oranges', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},
            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])
plt.yticks(rotation = 0)
plt.show()

"""# 3 - KNeighbors"""

df1 = df.drop('stroke', axis=1)

df1.columns

df3 = df['stroke']
df3

df1.shape

from sklearn.model_selection import train_test_split
df1_train, df1_test, df3_train, df3_test = train_test_split(df1,df3, test_size=0.2, random_state=42)

model = KNeighborsClassifier()
model.fit(df1_train, df3_train)
y_pred = model.predict(df1_test)
score = cross_val_score(model, df1_train, df3_train, cv = 6)
precision = precision_score(df3_test, y_pred)
roc = roc_auc_score(df3_test, y_pred)
recall = recall_score(df3_test, y_pred)
cm = confusion_matrix(df3_test, y_pred)
rm = accuracy_score(df3_test,y_pred)

print ('train score of KNN is', score.mean(),'%')
print ('--')
print ('Precision score is ', precision)
print ('--')
print ('ROC Score is', roc)
print ('--')
print ('Recall Score is ', recall)
print('accuracy score is ', rm)

y_pred_prob = model.predict_proba(df1_test)[:,1]
# instantiating the roc_cruve
fpr,tpr,threshols=roc_curve(y_test,y_pred_prob)

# plotting the curve
plt.figure(figsize = (8, 8))
plt.plot([0,1],[0,1],"k--",'r+')
figsize=(16,12)
plt.plot(fpr,tpr,color = '#b01717', label = 'AUC = %0.3f' % roc)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(" KNeighbors ROC Curve")
plt.legend()
plt.show()

plt.figure(figsize = (8, 5))
sns.heatmap(cm, cmap = 'Oranges', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},
            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])
plt.yticks(rotation = 0)
plt.show()

"""# 4 - Random Forest"""

model =  RandomForestClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
score = cross_val_score(model, X_train, y_train, cv = 6)
precision = precision_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
rm = accuracy_score(y_test,y_pred)

print ('train score of Random Forest is', score.mean(),'%')
print ('--')
print ('Precision score is ', precision)
print ('--')
print ('ROC Score is', roc)
print ('--')
print ('Recall Score is ', recall)
print('accuracy score is ', rm)

y_pred_prob = model.predict_proba(X_test)[:,1]
# instantiating the roc_cruve
fpr,tpr,threshols=roc_curve(y_test,y_pred_prob)

# plotting the curve
plt.figure(figsize = (8, 8))
plt.plot([0,1],[0,1],"k--",'r+')
figsize=(16,12)
plt.plot(fpr,tpr,color = '#b01717', label = 'AUC = %0.3f' % roc)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(" Random Forest ROC Curve")
plt.legend()
plt.show()

plt.figure(figsize = (8, 5))
sns.heatmap(cm, cmap = 'Oranges', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},
            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])
plt.yticks(rotation = 0)
plt.show()

"""## 5 - AdaBoost"""

model =  AdaBoostClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
score = cross_val_score(model, X_train, y_train, cv = 6)
precision = precision_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
rm = accuracy_score(y_test,y_pred)

print ('train score of Adaboost is', score.mean(),'%')
print ('--')
print ('Precision score is ', precision)
print ('--')
print ('ROC Score is', roc)
print ('--')
print ('Recall Score is ', recall)
print('accuracy score is ', rm)

y_pred_prob = model.predict_proba(X_test)[:,1]
# instantiating the roc_cruve
fpr,tpr,threshols=roc_curve(y_test,y_pred_prob)

# plotting the curve
plt.figure(figsize = (8, 8))
plt.plot([0,1],[0,1],"k--",'r+')
figsize=(16,12)
plt.plot(fpr,tpr,color = '#b01717', label = 'AUC = %0.3f' % roc)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(" AdaBoost ROC Curve")
plt.legend()
plt.show()

plt.figure(figsize = (8, 5))
sns.heatmap(cm, cmap = 'Oranges', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},
            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])
plt.yticks(rotation = 0)
plt.show()

@anvil.server.callable
def stroke_predict(gender_Male,gender_Female,age,Hypertension , heart_disease,ever_married_No,ever_married_yes,work_type_Never_worked,work_type_Private,work_type_Self_employed,work_type_children,work_type_Govt_job,Residence_type_Rural,Residence_type_Urban,avg_glucose_level,bmi,smoking_status_Unknown,smoking_status_formerly_smoked,smoking_status_smokes,smoking_status_never_smoked):
  classification = model.predict([[gender_Male,gender_Female,age,Hypertension , heart_disease,ever_married_No,ever_married_yes,work_type_Never_worked,work_type_Private,work_type_Self_employed,work_type_children,work_type_Govt_job,Residence_type_Rural,Residence_type_Urban,avg_glucose_level,bmi,smoking_status_Unknown,smoking_status_formerly_smoked,smoking_status_smokes,smoking_status_never_smoked]])

anvil.server.wait_forever()



